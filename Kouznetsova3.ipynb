{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# get_ipython().magic('matplotlib inline')\n",
    "from nltk import word_tokenize\n",
    "import re\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix, precision_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines = pd.read_csv('All-seasons.csv', sep=',',\n",
    "                           names=[\"season\", \"episode\", \"character\", \"line\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_to_keep = ['character', 'line']\n",
    "data = lines[cols_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "characters = ['Cartman', 'Kyle', 'Kenny', 'Stan']\n",
    "main_data = data[data['character'].isin(characters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_data = main_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "length = []\n",
    "character = []\n",
    "lines = []\n",
    "for m in main_data['line']:\n",
    "    m = m.strip()\n",
    "    m = m.lower()\n",
    "    words = word_tokenize(m)\n",
    "    length.append(len(words))\n",
    "    lines.append(m)\n",
    "for c in main_data['character']:\n",
    "    character.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame(\n",
    "    {'character': character,\n",
    "     'length': length,\n",
    "     'line': lines\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      length\n",
      "character                   \n",
      "Cartman   count  9774.000000\n",
      "          mean     17.663802\n",
      "          std      19.026016\n",
      "          min       1.000000\n",
      "          25%       7.000000\n",
      "          50%      12.000000\n",
      "          75%      22.000000\n",
      "          max     351.000000\n",
      "Kenny     count   881.000000\n",
      "          mean      8.861521\n",
      "          std       7.736653\n",
      "          min       2.000000\n",
      "          25%       4.000000\n",
      "          50%       7.000000\n",
      "          75%      11.000000\n",
      "          max     144.000000\n",
      "Kyle      count  7099.000000\n",
      "          mean     11.989294\n",
      "          std      11.124612\n",
      "          min       1.000000\n",
      "          25%       5.000000\n",
      "          50%       9.000000\n",
      "          75%      15.000000\n",
      "          max     159.000000\n",
      "Stan      count  7680.000000\n",
      "          mean     12.042578\n",
      "          std      11.029203\n",
      "          min       1.000000\n",
      "          25%       5.000000\n",
      "          50%       9.000000\n",
      "          75%      15.000000\n",
      "          max     177.000000\n"
     ]
    }
   ],
   "source": [
    "print(new_data.groupby('character').describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bow = CountVectorizer(tokenizer=tokenize, stop_words='english')\n",
    "bowed = bow.fit_transform(new_data['line'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_into_lemmas(message):\n",
    "    message = message.lower()\n",
    "    return word_tokenize(message)\n",
    "bow_transformer = CountVectorizer(analyzer=split_into_lemmas).fit(new_data['line'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines_bow = bow_transformer.transform(new_data['line'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer().fit(lines_bow)\n",
    "lines_tfidf = tfidf_transformer.transform(lines_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(lines_bow, new_data['character'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# НАИВНЫЙ БАЙЕС"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "character_detector = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#И accuracy и precision средние."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Cartman       0.58      0.71      0.63      1953\n",
      "      Kenny       0.92      0.74      0.82       157\n",
      "       Kyle       0.47      0.34      0.40      1440\n",
      "       Stan       0.48      0.47      0.47      1537\n",
      "\n",
      "avg / total       0.53      0.53      0.52      5087\n",
      "\n",
      "[[1380    4  252  317]\n",
      " [  32  116    7    2]\n",
      " [ 475    4  494  467]\n",
      " [ 511    2  305  719]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_nb = character_detector.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "print(confusion_matrix(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#У Кенни высокий precision и неплохой recall, однако у него намного меньше фраз чем у других персонажей \n",
    "# и у других персонажей оба результата хуже. Хуже всего классификатор распознает Кайла. Примерно столько же реплик, сколько\n",
    "# классификатор приписывает самому Кайлу, он приписывает еще и Кармену и Стэну."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Cartman       0.66      0.62      0.64      1953\n",
      "      Kenny       0.97      0.96      0.96       157\n",
      "       Kyle       0.45      0.45      0.45      1440\n",
      "       Stan       0.49      0.51      0.50      1537\n",
      "\n",
      "avg / total       0.56      0.55      0.55      5087\n",
      "\n",
      "[[1218    2  377  356]\n",
      " [   1  150    4    2]\n",
      " [ 311    2  651  476]\n",
      " [ 323    0  426  788]]\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(class_weight='balanced')\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(confusion_matrix(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Опять же результаты у Кенни наиболее высокие - и precision, и recall близки к 100%. Немного лучше начали распознаваться \n",
    "# реплики Кайла, но не намного. Для него классификатор все равно хуже всего работает\n",
    "# Средние показатели трех зарактеристик выросли на 2-3%, что немного, но все-таки хоть что-то.\n",
    "# Интересно, что классификатор также ни одну реплику, принадлежащую Стэну, не приписал Кенни. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Cartman       0.56      0.73      0.64      1953\n",
      "      Kenny       0.99      0.94      0.97       157\n",
      "       Kyle       0.45      0.31      0.37      1440\n",
      "       Stan       0.46      0.42      0.44      1537\n",
      "\n",
      "avg / total       0.51      0.52      0.51      5087\n",
      "\n",
      "[[1427    0  222  304]\n",
      " [   6  148    3    0]\n",
      " [ 533    1  443  463]\n",
      " [ 570    0  315  652]]\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=80)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred_rf = rfc.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# У Random Forest пока наихудшие результаты, хотя опять же не намного - на 1-2% хуже чем у наивного байеса.\n",
    "# Лучше всего по прежнему классифицируются реплики Кенни. Хуже всего по прежнему Кайл.\n",
    "# Ни одна реплика Стэна и Картмена не была классифицирована как реплика Кенни, и всего одна реплика Кайла попала к Кенни, \n",
    "# из-за чего у него такой высокий precision - 99%.\n",
    "# Этот классификатор лучший из классификатор в правильном нахождении реплик Картмена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RANDOM TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Cartman       0.52      0.58      0.55      1953\n",
      "      Kenny       0.99      0.94      0.97       157\n",
      "       Kyle       0.40      0.35      0.37      1440\n",
      "       Stan       0.41      0.41      0.41      1537\n",
      "\n",
      "avg / total       0.47      0.48      0.47      5087\n",
      "\n",
      "[[1134    0  357  462]\n",
      " [   6  148    1    2]\n",
      " [ 503    1  502  434]\n",
      " [ 520    0  382  635]]\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(min_samples_split=5)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_clf = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_clf))\n",
    "print(confusion_matrix(y_test, y_pred_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Теперь у Random Tree хуже всего результаты. Так же как и вдругих классификаторах, лучше всего определялся Кенни, \n",
    "# хуже всего Кайл. Как и у Random Forest, здесь почти стопроцентная precision у Кенни, так как только одна реплика Кайла была\n",
    "# неправильно приписана Кенни."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
